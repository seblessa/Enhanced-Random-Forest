{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho prático AC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalho realizado por:\n",
    "\n",
    "Margarida Vila-chã, 20210504\n",
    "\n",
    "Miguel Duarte Silva, 20210504\n",
    "\n",
    "Sebastião Lessa, 202103238\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo escolhido e breve explicação:\n",
    "\n",
    "O algoritmo escolhido pelo nosso grupo foi o Random Forrest.\n",
    "\n",
    "Este algoritmo é um algoritmo de aprendizagem computacional supervisionado. Ele usa uma combinação de árvores de decisão aleatórias. O processo começa com a criação de um grande número de árvores (floresta), em que cada uma das árvores criadas é treinada com uma amostra diferente. Isto permite a criação de árvores suficientemente diferentes, o que leva a que elas juntas consigam lidar com uma ampla variedade de situações, reduzindo o risco de overffitting.\n",
    "\n",
    "Baseamos-nos nos seguintes data-sets:\n",
    "\n",
    "- [credit-g](https://www.openml.org/search?type=run&id=591&collections.id=99&run_task.task_id=31&sort=date)\n",
    "- [breast-w](https://www.openml.org/search?type=run&id=7413&collections.id=99&run_task.task_id=15)\n",
    "- [qsar-biodeg](https://www.openml.org/search?type=run&id=519587&collections.id=99&run_task.task_id=9957)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alteração escolhida\n",
    "A alteração que o nosso grupo decidiu fazer no codigo fonte obtido foi a de considerar a utilização de outros tipos de critérios de divisão. O critério pré definido no nosso código fonte é o de entropia, por isso vamos testar com o gini e com o classification error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T18:01:28.593025Z",
     "start_time": "2023-05-17T18:01:28.453152Z"
    }
   },
   "source": [
    "## Import das bibliotecas necessárias:"
   ],
   "outputs": [],
   "execution_count": 482
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo implementado, sem alteração"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, criterion='gini', max_depth=None):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        label_counts = Counter(y)\n",
    "\n",
    "        # Base cases: check termination conditions\n",
    "        if len(label_counts) == 1:\n",
    "            # All samples belong to the same class\n",
    "            return {'class': label_counts.most_common(1)[0][0]}\n",
    "\n",
    "        if depth == self.max_depth or num_samples < 2:\n",
    "            # Reached maximum depth or too few samples remaining\n",
    "            return {'class': label_counts.most_common(1)[0][0]}\n",
    "\n",
    "        if num_features == 0:\n",
    "            # No features remaining to split on\n",
    "            return {'class': label_counts.most_common(1)[0][0]}\n",
    "\n",
    "        # Determine the best feature and split point\n",
    "        best_feature, best_split_point = self._get_best_split(X, y)\n",
    "\n",
    "        # Create the tree node\n",
    "        node = {'feature': best_feature, 'split_point': best_split_point}\n",
    "\n",
    "        # Split the data based on the best feature and split point\n",
    "        left_mask = X[:, best_feature] <= best_split_point\n",
    "        right_mask = X[:, best_feature] > best_split_point\n",
    "\n",
    "        left_X, left_y = X[left_mask], y[left_mask]\n",
    "        right_X, right_y = X[right_mask], y[right_mask]\n",
    "\n",
    "        # Recursively build the left and right subtrees\n",
    "        node['left'] = self._build_tree(left_X, left_y, depth + 1)\n",
    "        node['right'] = self._build_tree(right_X, right_y, depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _compute_score(self, y):\n",
    "        # Compute the score based on the selected criterion\n",
    "        if self.criterion == 'gini':\n",
    "            return self._gini_index(y)\n",
    "        elif self.criterion == 'entropy':\n",
    "            return self._entropy(y)\n",
    "        elif self.criterion == 'log_loss':\n",
    "            return self._log_loss(y)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid criterion: {}\".format(self.criterion))\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions for the input data\n",
    "        predictions = np.zeros(len(X))\n",
    "\n",
    "        for i, sample in enumerate(X):\n",
    "            predictions[i] = self._traverse_tree(sample, self.tree)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def _traverse_tree(self, sample, node):\n",
    "        if 'class' in node:\n",
    "            # Leaf node: return the predicted class\n",
    "            return node['class']\n",
    "\n",
    "        # Internal node: recursively traverse the tree\n",
    "        feature = node['feature']\n",
    "        split_point = node['split_point']\n",
    "\n",
    "        if sample[feature] <= split_point:\n",
    "            return self._traverse_tree(sample, node['left'])\n",
    "        else:\n",
    "            return self._traverse_tree(sample, node['right'])\n",
    "\n",
    "    @staticmethod\n",
    "    def _gini_index(y):\n",
    "        # Compute the Gini index for a given set of labels\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        gini = 1.0 - np.sum(probabilities ** 2)\n",
    "        return gini\n",
    "\n",
    "    @staticmethod\n",
    "    def _entropy(y):\n",
    "        # Compute the entropy for a given set of labels\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    @staticmethod\n",
    "    def _log_loss(y):\n",
    "        # Compute the logarithmic loss for a given set of labels\n",
    "        num_samples = len(y)\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        class_counts = Counter(y)\n",
    "        class_probabilities = np.array([class_counts[c] / num_samples for c in unique_classes])\n",
    "\n",
    "        return -np.sum(class_probabilities * np.log2(class_probabilities))\n",
    "\n",
    "    def _get_best_split(self, X, y):\n",
    "        best_feature = None\n",
    "        best_split_point = None\n",
    "        best_score = -np.inf\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            for value in unique_values:\n",
    "                left_mask = X[:, feature] <= value\n",
    "                right_mask = X[:, feature] > value\n",
    "                left_labels = y[left_mask]\n",
    "                right_labels = y[right_mask]\n",
    "\n",
    "                if len(left_labels) > 0 and len(right_labels) > 0:\n",
    "                    score = self._compute_score(left_labels) * len(left_labels) + \\\n",
    "                            self._compute_score(right_labels) * len(right_labels)\n",
    "                    if score > best_score:\n",
    "                        best_feature = feature\n",
    "                        best_split_point = value\n",
    "                        best_score = score\n",
    "\n",
    "        return best_feature, best_split_point\n",
    "\n",
    "    def get_best_criterion(self, X, y, criteria):\n",
    "        best_score = 0.0\n",
    "        best_criterion = None\n",
    "\n",
    "        for criterion in criteria:\n",
    "            self.criterion = criterion\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            self.fit(X_train, y_train)\n",
    "            y_pred = self.predict(X_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_criterion = criterion\n",
    "\n",
    "        return best_criterion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "class Custom_RF(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.estimators = []\n",
    "        # self.max_depth = self._get_best_max_depth(X, y)\n",
    "        # self.n_estimators = self._get_best_n_estimators(X, y)\n",
    "\n",
    "        criteria = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            bootstrap_indices = resample(range(len(X)), replace=True)\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "\n",
    "            tree = DecisionTree(self.max_depth)\n",
    "            tree.set_best_criterion(X_bootstrap, y_bootstrap, criteria)\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(X), len(self.estimators)))\n",
    "\n",
    "        for i, estimator in enumerate(self.estimators):\n",
    "            predictions[:, i] = estimator.predict(X)\n",
    "\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=predictions)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_best_max_depth(X, y):\n",
    "        param_grid = {'max_depth': [None, 5, 10, 15, 20]}\n",
    "        rf_classifier = Custom_RF(n_estimators=1)  # Temporarily create an instance for grid search\n",
    "        grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X, y)\n",
    "        best_max_depth = grid_search.best_params_['max_depth']\n",
    "        return best_max_depth\n",
    "\n",
    "    def _get_best_n_estimators(self, X, y):\n",
    "        param_grid = {'n_estimators': [50, 100, 150, 200, 250]}\n",
    "        rf_classifier = Custom_RF(max_depth=self.max_depth)  # Temporarily create an instance for grid search\n",
    "        grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X, y)\n",
    "        best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "        return best_n_estimators"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.355619Z",
     "start_time": "2023-05-18T18:33:02.264534Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes para cada dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "def test_model(dataset, model):\n",
    "\n",
    "    X=dataset.iloc[:,1:-1].values\n",
    "    y=dataset.iloc[:,-1].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.355678Z",
     "start_time": "2023-05-18T18:33:02.267604Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET 1 - Cancro da mama"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.358177Z",
     "start_time": "2023-05-18T18:33:02.281940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id  Clump_Thickness  Cell_Size_Uniformity  Cell_Shape_Uniformity  \\\n0   1                5                     1                      1   \n1   2                5                     4                      4   \n2   3                3                     1                      1   \n3   4                6                     8                      8   \n4   5                4                     1                      1   \n\n   Marginal_Adhesion  Single_Epi_Cell_Size Bare_Nuclei  Bland_Chromatin  \\\n0                  1                     2           1                3   \n1                  5                     7          10                3   \n2                  1                     2           2                3   \n3                  1                     3           4                3   \n4                  3                     2           1                3   \n\n   Normal_Nucleoli  Mitoses  Class  \n0                1        1      0  \n1                2        1      0  \n2                1        1      0  \n3                7        1      0  \n4                1        1      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Clump_Thickness</th>\n      <th>Cell_Size_Uniformity</th>\n      <th>Cell_Shape_Uniformity</th>\n      <th>Marginal_Adhesion</th>\n      <th>Single_Epi_Cell_Size</th>\n      <th>Bare_Nuclei</th>\n      <th>Bland_Chromatin</th>\n      <th>Normal_Nucleoli</th>\n      <th>Mitoses</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>6</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class']=df['Class'].map({'benign': 0, 'malignant': 1})\n",
    "df['Bare_Nuclei'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['Bare_Nuclei'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 1 - Random Forest (sklearn) com o critério default (gini)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.375300Z",
     "start_time": "2023-05-18T18:33:02.287564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9658536585365853\n"
     ]
    }
   ],
   "source": [
    "test_model(df, RF())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 2 - Random Forest (sklearn) com o critério entropy"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9560975609756097\n"
     ]
    }
   ],
   "source": [
    "test_model(df, RF(criterion='entropy'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.459545Z",
     "start_time": "2023-05-18T18:33:02.355069Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 3 - Random Forest (sklearn) com o critério log_loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.511898Z",
     "start_time": "2023-05-18T18:33:02.441106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9560975609756097\n"
     ]
    }
   ],
   "source": [
    "test_model(df, RF(criterion='log_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 4 - Random Forest (Custom)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T18:33:02.558452Z",
     "start_time": "2023-05-18T18:33:02.538869Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[200], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtest_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCustom_RF\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[194], line 8\u001B[0m, in \u001B[0;36mtest_model\u001B[0;34m(dataset, model)\u001B[0m\n\u001B[1;32m      4\u001B[0m y\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39miloc[:,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m      6\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y,test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, accuracy_score(y_test, model\u001B[38;5;241m.\u001B[39mpredict(X_test)))\n",
      "Cell \u001B[0;32mIn[193], line 15\u001B[0m, in \u001B[0;36mCustom_RF.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     12\u001B[0m criteria \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgini\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators):\n\u001B[0;32m---> 15\u001B[0m     tree \u001B[38;5;241m=\u001B[39m DecisionTree(\u001B[43mbest_criterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriteria\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_features)\n\u001B[1;32m     16\u001B[0m     tree\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators\u001B[38;5;241m.\u001B[39mappend(tree)\n",
      "Cell \u001B[0;32mIn[192], line 7\u001B[0m, in \u001B[0;36mbest_criterion\u001B[0;34m(X, y, criteria)\u001B[0m\n\u001B[1;32m      5\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y,test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      6\u001B[0m tree \u001B[38;5;241m=\u001B[39m DecisionTree(criterion\u001B[38;5;241m=\u001B[39mcriterion)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m      9\u001B[0m score \u001B[38;5;241m=\u001B[39m accuracy_score(y, y_pred)\n",
      "Cell \u001B[0;32mIn[191], line 8\u001B[0m, in \u001B[0;36mDecisionTree.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[191], line 14\u001B[0m, in \u001B[0;36mDecisionTree._build_tree\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y)) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m: y[\u001B[38;5;241m0\u001B[39m]}\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_features\u001B[49m:\n\u001B[1;32m     15\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mTypeError\u001B[0m: '<=' not supported between instances of 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "test_model(df, Custom_RF())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2 - Biodeg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.542923Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('biodeg.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 1 - Random Forest (sklearn) com o critério default (gini)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.551549Z"
    }
   },
   "outputs": [],
   "source": [
    "test_model(df, RF())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 2 - Random Forest (sklearn) com o critério entropy"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, RF(criterion='entropy'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.551935Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 3 - Random Forest (sklearn) com o critério log_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, RF(criterion='log_loss'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.552013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 4 - Random Forest (Custom)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, Custom_RF())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.552087Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset 2 - Diabetes"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"'class'\"]=df[\"'class'\"].map({'tested_positive': 0, 'tested_negative': 1})\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.552220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 1 - Random Forest (sklearn) com o critério default (gini)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, RF())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.552280Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 2 - Random Forest (sklearn) com o critério entropy\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, RF(criterion='entropy'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.552350Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 3 - Random Forest (sklearn) com o critério log_loss\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, RF(criterion='log_loss'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.552430Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teste 4 - Random Forest (Custom)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model(df, Custom_RF())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T18:33:02.553563Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
